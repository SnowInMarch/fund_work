import matplotlib.pyplot as plt # to plot graphs
import pandas as pd             # to work with tables and storing/manipulating data
import numpy as np              # just in case
import datetime as dt           # timing
import requests                 # connecting to API's
import json                     # reading json files
from mpl_finance import candlestick_ohlc  # to draw candlesticks
import matplotlib.dates as mdates           # to convert dates to matplotlib supported format
import random
from sklearn.linear_model import LinearRegression  # linear regression modelling tool for B1 and B0 (seems to work fine)
import statsmodels.tsa.stattools as ts
import scipy.stats as stats
from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()
from statsmodels.tsa.stattools import coint, adfuller
import statsmodels.api as sm
import statsmodels
import csv
from playsound import playsound
import time
import datetime



def get_stock_data(symbol, interval):
    root_url = 'https://api.binance.com/api/v1/klines'
    url = root_url + '?symbol=' + symbol + '&interval=' + interval
    # print(url)
    data = json.loads(requests.get(url).text)
    df = pd.DataFrame(data)
    df.columns = ['open_time', 'o', 'h', 'l', 'c', 'volume',
                  'close_time', 'qav', 'num_trades',
                  'taker_base_vol', 'taker_quote_vol', 'ignore']
    df.index = [dt.datetime.fromtimestamp(x/1000.0) for x in df.close_time]
    df['returns'] = df['c'].astype(float).pct_change(1)

    # print(df)
    return df


# I don't think that I need this one.
def get_many_stocks_data():
    symbols = json.loads(requests.get('https://api.binance.com/api/v1/exchangeInfo').text)
    symbols_btc = [symbol['symbol'] for symbol in symbols['symbols'] if symbol['quoteAsset'] == 'BTC']
    print(f'SYMBOLS FOR BTC PAIR: {symbols_btc}')

    symbols_usdt = [symbol['symbol'] for symbol in symbols['symbols'] if symbol['quoteAsset'] == 'USDT']
    print(f'SYMBOLS FOR USDT PAIR:{symbols_usdt}')

    symbols_eth = [symbol['symbol'] for symbol in symbols['symbols'] if symbol['quoteAsset'] == 'ETH']
    print(f'SYMBOLS FOR ETH PAIR:{symbols_eth}')
    price_data = []

    # for symbol in symbols_usdt:
    #     data = get_stock_data(symbol, '1d')
    #     price_data.append(data['c'].astype('float'))
    # print(price_data)


def draw_chart(stock, symbol):

    stock['21ma'] = stock['c'].rolling(window=21).mean()
    # hotusdt = stock['close'].astype('float')
    plt.figure(figsize=(13, 6))

    ax1 = plt.subplot2grid((10, 1), (0, 0), rowspan=7, colspan=1)              # defines 1st axis
    ax2 = plt.subplot2grid((10, 1), (7, 0), rowspan=3, colspan=1, sharex=ax1)  # defines 2nd axis (under 1st one)
    plt.title(f'{symbol}\n -----')

    ax1.plot(stock.index, stock['c'].astype('float'))  # SHOWS MAIN STOCK PRICE ON GRAPH
    ax1.plot(stock.index, stock['21ma'].astype('float'))   # SHOWS 21MA ON GRAPH
    ax2.plot(stock.index, stock['returns'].astype('float'))  # shows returns (stationary data) on 2nd axis graph
    plt.show()


# draws a candlestick chart for the pair
def draw_candle_chart(stock):  # NEED TO MAKE DATES DISPLAY PROPERLY
    # also try to fix the volume, coz it fucks up the graph
    stock.index = [mdates.date2num(dt.datetime.fromtimestamp(x/1000)) for x in stock.open_time]
    # print(stock)
    ax1 = plt.subplot2grid((6, 1), (0, 0), rowspan=5, colspan=1)  # defines 1st axis
    ax2 = plt.subplot2grid((6, 1), (5, 0), rowspan=1, colspan=1, sharex=ax1)  # defines 2nd axis (under 1st one)
    candlestick_ohlc(ax1, stock.values.astype('float'), width=2, colorup='g')
    # candlestick2_ohlc(ax1, stock['o'].astype('float'), stock['h'].astype('float'), stock['l'].astype('float'), stock['c'].astype('float'), width=0.7, colorup='g')
    # candlestick2_ohlc()
    # ax2.bar(stock.index, stock['volume'].astype('float'), width=0.3)  #shows volume on 2nd axis graph
    plt.show()

# prints many graphs on the same chart
def compile_data(stock1, stock2, timeframe):
    price_data = []
    # available_pairs = ['HOTBTC', 'HBARBTC', 'LINKBTC', 'RENBTC', 'ETHBTC', 'NEOBTC', 'XRPBTC', 'TRXBTC', 'CHZBTC', 'VETBTC', 'ONTBTC', 'QTUMBTC', 'ATOMBTC', 'XLMBTC', 'FETBTC', 'BATBTC', 'ETCBTC', 'XMRBTC', 'MATICBTC', 'ADABTC', 'BEAMBTC', 'KAVABTC', 'ICXBTC', 'ARPABTC', 'XTZBTC', 'NKNBTC', 'COCOSBTC', 'ERDBTC', 'EOSBTC', 'NULSBTC', 'IOTABTC', 'DOGEBTC', 'ONEBTC', 'TOMOBTC', 'OMGBTC', 'HCBTC', 'LTCBTC', 'MTLBTC', 'STXBTC', 'ZILBTC', 'WAVESBTC', 'BANDBTC', 'DUSKBTC', 'ALGOBTC', 'STORMBTC', 'FUNBTC', 'PERLBTC', 'CELRBTC', 'THETABTC', 'KEYBTC', 'FTMBTC', 'ENJBTC', 'GTOBTC']
    # available_pairs = ['BANDBTC', 'ONEBTC', 'PERLBTC', 'KAVABTC', 'CELRBTC']
    # ALL MARGIN TRADING ON BINANCE ---  available_pairs = ['MATICBTC', 'ETHBTC', 'BNBBTC', 'LINKBTC', 'XRPBTC', 'ADABTC', 'XMRBTC', 'LTCBTC', 'EOSBTC', 'XTZBTC', 'VETBTC', 'DASHBTC', 'ATOMBTC', 'TRXBTC', 'QTUMBTC', 'BCHBTC', 'NEOBTC', 'BATBTC', 'IOSTBTC', 'ZECBTC', 'ONTBTC', 'XLMBTC', 'ETCBTC', 'IOTABTC']
    # available_pairs = ['ETHBTC', 'BNBBTC', 'LINKBTC', 'XRPBTC', 'ADABTC', 'XMRBTC', 'LTCBTC', 'EOSBTC', 'XTZBTC', 'VETBTC', 'DASHBTC', 'ATOMBTC', 'TRXBTC', 'QTUMBTC', 'BCHBTC', 'NEOBTC', 'BATBTC', 'IOSTBTC', 'ZECBTC', 'ONTBTC', 'XLMBTC', 'ETCBTC', 'IOTABTC']
    # available_pairs = random.choices(pairs, k=3)  # chooses random 3 pairs (for analysis)
    available_pairs = [stock1, stock2]
    for pair in available_pairs:
        data = get_stock_data(pair, timeframe)
        # print(pair)
        price_data.append(data['c'].astype('float'))
    # print(price_data)
    combination_graph = pd.concat(price_data, axis=1)
    combination_graph.columns = available_pairs
    combination_graph.div(combination_graph.iloc[0]).plot(figsize=(16, 9))
    plt.show()


def clean_data(data):
    price_data = np.array(data['c'].astype('float'))
    return price_data


# sklearn funktion to measure linear regression (линейная регрессия)
def find_linear_regression(first_pair_data, second_pair_data):
    reg = LinearRegression(fit_intercept=True)
    reg.fit(first_pair_data.reshape(-1, 1), second_pair_data.reshape(-1, 1))
    regression_coefficient, regression_interception = reg.coef_[0,0], reg.intercept_[0]
    print(f' b1: {regression_coefficient}, b0: {regression_interception}')
    return regression_coefficient, regression_interception


# my own version of function to measure linear regression
def find_regression(symbol1, symbol2, first_pair_data, second_pair_data):

    mean_first_pair = np.mean(first_pair_data)

    mean_second_pair = np.mean(second_pair_data)

    print(f'mean x : {mean_first_pair}, mean y :{mean_second_pair}')
    # print(mean_check1, mean_check2)
    sum_up = 0
    sum_down = 0
    new_x_data = []
    new_y_data = []
    for x in first_pair_data:
        x_value = x - mean_first_pair
        new_x_data.append(x_value)

    for y in second_pair_data:
        y_value = y - mean_second_pair
        new_y_data.append(y_value)

    multiplied = [x*y for x, y in zip(new_x_data, new_y_data)]

    for item in multiplied:
        sum_up += item

    for x in first_pair_data:
        x_value = (x - mean_first_pair)**2
        sum_down += x_value

    b1 = sum_up / sum_down
    b0 = mean_second_pair - b1*mean_first_pair
    print(f' b1: {b1}, b0: {b0}')
    return b1, b0


# residuals (errors) - how far away each given point is from line of best fir (b1)
def residuals(first_pair_values, second_pair_values, regression_coefficient, regression_interception):
    return first_pair_values - (regression_coefficient * second_pair_values + regression_interception)


# measures mean value of the data (среднее значение)
def find_mean(data):
    sum = 0
    for item in data:
        sum += item
    mean = sum / len(data)
    print(f'sum: {round(sum, 10)}, len:{len(data)}, mean: {round(mean, 10)}')
    return mean


# measures standart deviation (стандартное отклонение)
def find_stdev(data):
    standart_deviation = np.std(data)
    print_st_dev = format(standart_deviation, '.12f')
    print(f'st.dev: {print_st_dev}')
    return standart_deviation


# how many datapoints fall within 1 standart deviation
def observations_within_stdev(data):
    mean = np.mean(data)
    st_dev = np.std(data)
    lower_threshold = mean - st_dev
    upper_threshold = mean + st_dev
    valid_data = []
    for item in data:
        if upper_threshold > item > lower_threshold:
            valid_data.append(item)

    percentage_within_1std = format((len(valid_data)/len(data) * 100), '.2f')
    print(f'-1 st.dev < N < 1 st.dev: {len(valid_data)} out of {len(data)} , {percentage_within_1std} %')


# how far away the residuals(errors) are from the mean (y - mean) LOOK UP THE PRECISE FORMULA PLS GOOD SIR FIX FIX FIX
def residuals_mean(data):
    mean = np.mean(data)
    residual_from_mean_data = [mean - item for item in data]
    return residual_from_mean_data  # SST RELATED STUFF


def write_log(message):
    with open('statistical_analysis_log.csv', 'a') as file:
        wfile = csv.writer(file)
        wfile.writerow(message)


# SSE/SST - how many errors out of all data  <<<<<<<< WORK ON IT
def sst_sse_ssr(data, data2):
    sse = 0
    squared_data = [item**2 for item in data]
    for item in squared_data:
        sse += item

    residuals_mean(data2)  # need to re-check
    sst = 0
    squared_data = [item**2 for item in data2]
    for item in squared_data:
        sst += item

    ssr = sst - sse

    r_squared = ssr/sst
    # ADD SST, SSR


def draw_scatter_correlation(first_pair, second_pair, timeframe):
    first_pair_data = get_stock_data(first_pair, timeframe)
    second_pair_data = get_stock_data(second_pair, timeframe)
    first_pair_data_clean = clean_data(first_pair_data)
    second_pair_data_clean = clean_data(second_pair_data)

    plt.scatter(first_pair_data_clean, second_pair_data_clean, color='b', marker='o', s=10, label='scatter of prices')
    plt.show()


def draw_spread(data, symbol1, symbol2):
    plt.figure(figsize=(13, 6))
    ax1 = plt.subplot2grid((10, 1), (0, 0), rowspan=7, colspan=1)              # defines 1st axis

    ax1.plot(data['spread'])
    ax1.axhline(data['spread'].mean(), color='red', linestyle='--')
    ax1.axhline(data['spread'].mean() + data['spread'].std(), color='y', linestyle='--')
    ax1.axhline(data['spread'].mean() - data['spread'].std(), color='y', linestyle='--')
    ax1.axhline(data['spread'].mean() + 2*data['spread'].std(), color='g', linestyle='--')
    ax1.axhline(data['spread'].mean() - 2*data['spread'].std(), color='g', linestyle='--')
    plt.title(symbol1 + ' ' + symbol2 + ' spread')
    plt.legend(['Price Spread', 'Mean', 'Mean +/- Standart Deviation', 'Mean +/- 2 Standart Deviations'])
    plt.show()


# AUGMENTED DICKEY FULLER TEST
def check_for_stationarity(data, cutoff=0.01):
    # dont forget that we are estimating, why dont we put on a stricter test?
    values = adfuller(data)
    p_value = adfuller(data)[1]
    print(values)
    print(f'p-value:  {p_value}')
    if p_value < cutoff:
        print('p-value = ' + format(p_value, '.15f') + ' The series is likely stationary LOL.')
        return p_value
    else:
        print('p-value = ' + format(p_value, '.15f') + ' The series is likely non-stationary.')
        return p_value



def draw_4_charts(first_pair, second_pair, timeframe):

    first_pair_data = get_stock_data(first_pair, timeframe)
    second_pair_data = get_stock_data(second_pair, timeframe)
    first_pair_data_clean = clean_data(first_pair_data)
    second_pair_data_clean = clean_data(second_pair_data)

    b1, b0 = find_linear_regression(first_pair_data_clean, second_pair_data_clean)
    first_pair_data['returns'] = first_pair_data['c'].astype(float).pct_change(1)
    first_pair_returns = first_pair_data['returns'].astype(float).dropna()
    # plt.
    second_pair_data['returns'] = second_pair_data['c'].astype(float).pct_change(1)
    second_pair_returns = second_pair_data['returns'].astype(float).dropna()
# THIS IS 2 GRAPH, CORRELATION OF PRICES
########################################################################
    all_data = pd.DataFrame()
    all_data['first_data_close'] = (first_pair_data['c'])
    all_data['second_data_close'] = (second_pair_data['c'])
    all_data['spread'] = all_data['second_data_close'].astype(float) - b1 * all_data['first_data_close'].astype(float)
    all_data['spread2'] = all_data['first_data_close'].astype(float) - b1 * all_data['second_data_close'].astype(float)
    # print(all_data)
    spread_mean = np.mean(all_data['spread'])
    spread_st_dev = np.std(all_data['spread'])
# 4 th GRAPH, SPREAD , MEAN , +- 1&2 STANDARD DEVIATIONS
#########################################################################
    plt.figure(figsize=(15, 8))
    ax1 = plt.subplot2grid((15, 18), (0, 0), rowspan=6, colspan=6)
    ax2 = plt.subplot2grid((15, 18), (0, 6), rowspan=6, colspan=6)
    ax3 = plt.subplot2grid((15, 18), (7, 0), rowspan=6, colspan=18)
    plt.title(f'{first_pair} ----- {second_pair}')

    # ax1.plot(all_data.index, all_data['second_data_close'].astype('float'))  # SHOWS MAIN STOCK PRICE ON GRAPH

    ax1.scatter(first_pair_data_clean, second_pair_data_clean, color='b', marker='o', s=10, label='scatter of prices')
    ax2.scatter(first_pair_returns, second_pair_returns, color='b', marker='o', s=10)

    ax3.plot(all_data['spread'])
    ax3.axhline(all_data['spread'].mean(), color='red', linestyle='--')
    ax3.axhline(all_data['spread'].mean() + all_data['spread'].std(), color='y', linestyle='--')
    ax3.axhline(all_data['spread'].mean() - all_data['spread'].std(), color='y', linestyle='--')
    ax3.axhline(all_data['spread'].mean() + 2 * all_data['spread'].std(), color='g', linestyle='--')
    ax3.axhline(all_data['spread'].mean() - 2 * all_data['spread'].std(), color='g', linestyle='--')
    plt.show()


# Full analysis includes:
# finding mean, standart deviation,
# % of observations within 1 st.dev,
# linear regression, drawing scatter plot
# finding residuals for data, (SSE in future) !!!!!!! think about it , maybe useful
# finding
# building spread

def full_analysis(symbol1, symbol2, timeframe):
    print(f'[ {symbol1} {symbol2} {timeframe} ]')
    print('[' + symbol1 + ']')

    # getting the symbol1 data and cleaning it
    first_pair_data = get_stock_data(symbol1, timeframe)
    first_pair_clean = clean_data(first_pair_data)

    # getting returns data (% change)
    first_pair_data['returns'] = first_pair_data['c'].astype(float).pct_change(1)
    first_pair_returns = first_pair_data['returns'].astype(float).dropna()

    # looking for mean, st.dev, and observations within st.dev for symbol1
    mean_first_pair = find_mean(first_pair_clean)
    st_dev_first = find_stdev(first_pair_clean)
    observations_within_stdev(first_pair_clean)

    print('[' + symbol2 + ']')

    # getting the symbol2 data and cleaning it
    second_pair_data = get_stock_data(symbol2, timeframe)
    second_pair_clean = clean_data(second_pair_data)

    # getting returns data (% change)
    second_pair_data['returns'] = second_pair_data['c'].astype(float).pct_change(1)
    second_pair_returns = second_pair_data['returns'].astype(float).dropna()

    # looking for mean, st.dev, and observations within st.dev for symbol2
    mean_second_pair = find_mean(second_pair_clean)
    st_dev_second = find_stdev(second_pair_clean)
    observations_within_stdev(second_pair_clean)

    print('[regression analyis]')
    b1, b0 = find_regression(symbol1, symbol2, first_pair_clean, second_pair_clean)
    find_linear_regression(first_pair_clean, second_pair_clean)

    print('[looking for residuals]')
    residuals_data = residuals(first_pair_clean, second_pair_clean, b1, b0)

    print('[building spread]')
    all_data = pd.DataFrame()
    all_data['first_data_close'] = (first_pair_data['c'])
    all_data['second_data_close'] = (second_pair_data['c'])
    all_data['spread'] = all_data['second_data_close'].astype(float) - b1 * all_data['first_data_close'].astype(float)
    # print(all_data)
    spread_mean = np.mean(all_data['spread'])
    spread_st_dev = np.std(all_data['spread'])
    print(f'mean of spread : {spread_mean}')
    print(f'st_dev of spread: {spread_st_dev}')

    print('[checking for stationarity of spread]')
    p_value = check_for_stationarity(all_data['spread'])
    # if p_value < 0.01:
    #     print('[plotting graphs]')
    #     compile_data(symbol1, symbol2, timeframe)  # 1st graph, 2 charts together
    #     draw_scatter_correlation(symbol1, symbol2, timeframe) # 2nd graph, scatter plot of 2 prices
    #     plt.scatter(first_pair_returns, second_pair_returns, color='b', marker='o', s=10) # 3rd graph, scatter plot of returns
    #     plt.show()
    #     draw_spread(all_data, symbol1, symbol2) # 4th graph, chart of spread between 2
    return(p_value)

def full_analysis_watch(symbol1, symbol2, timeframe):
    print(f'[ {symbol1} {symbol2} {timeframe} ]')
    print('[' + symbol1 + ']')

    # getting the symbol1 data and cleaning it
    first_pair_data = get_stock_data(symbol1, timeframe)
    first_pair_clean = clean_data(first_pair_data)

    # getting returns data (% change)
    first_pair_data['returns'] = first_pair_data['c'].astype(float).pct_change(1)
    first_pair_returns = first_pair_data['returns'].astype(float).dropna()

    # looking for mean, st.dev, and observations within st.dev for symbol1
    mean_first_pair = find_mean(first_pair_clean)
    st_dev_first = find_stdev(first_pair_clean)
    observations_within_stdev(first_pair_clean)

    print('[' + symbol2 + ']')

    # getting the symbol2 data and cleaning it
    second_pair_data = get_stock_data(symbol2, timeframe)
    second_pair_clean = clean_data(second_pair_data)

    # getting returns data (% change)
    second_pair_data['returns'] = second_pair_data['c'].astype(float).pct_change(1)
    second_pair_returns = second_pair_data['returns'].astype(float).dropna()

    # looking for mean, st.dev, and observations within st.dev for symbol2
    mean_second_pair = find_mean(second_pair_clean)
    st_dev_second = find_stdev(second_pair_clean)
    observations_within_stdev(second_pair_clean)

    print('[regression analyis]')
    b1, b0 = find_regression(symbol1, symbol2, first_pair_clean, second_pair_clean)
    find_linear_regression(first_pair_clean, second_pair_clean)

    print('[looking for residuals]')
    residuals_data = residuals(first_pair_clean, second_pair_clean, b1, b0)

    print('[building spread]')
    all_data = pd.DataFrame()
    all_data['first_data_close'] = (first_pair_data['c'])
    all_data['second_data_close'] = (second_pair_data['c'])
    all_data['spread'] = all_data['second_data_close'].astype(float) - b1 * all_data['first_data_close'].astype(float)
    # print(all_data)
    spread_mean = np.mean(all_data['spread'])
    spread_st_dev = np.std(all_data['spread'])
    print(f'mean of spread : {spread_mean}')
    print(f'st_dev of spread: {spread_st_dev}')
    last_spread_data = all_data['spread'][-1]
    print(all_data['spread'])
    print(last_spread_data)
    print('[checking for stationarity of spread]')
    p_value = check_for_stationarity(all_data['spread'])
    # if p_value < 0.01:
    #     print('[plotting graphs]')
    #     compile_data(symbol1, symbol2, timeframe)  # 1st graph, 2 charts together
    #     draw_scatter_correlation(symbol1, symbol2, timeframe) # 2nd graph, scatter plot of 2 prices
    #     plt.scatter(first_pair_returns, second_pair_returns, color='b', marker='o', s=10) # 3rd graph, scatter plot of returns
    #     plt.show()
    # draw_spread(all_data, symbol1, symbol2) # 4th graph, chart of spread between 2
    return p_value, spread_mean, spread_st_dev, last_spread_data, all_data


def full_analysis_and_plots(symbol1, symbol2, timeframe):
    print(f'[ {symbol1} {symbol2} {timeframe} ]')
    print('[' + symbol1 + ']')

    # getting the symbol1 data and cleaning it
    first_pair_data = get_stock_data(symbol1, timeframe)
    first_pair_clean = clean_data(first_pair_data)

    # getting returns data (% change)
    first_pair_data['returns'] = first_pair_data['c'].astype(float).pct_change(1)
    first_pair_returns = first_pair_data['returns'].astype(float).dropna()

    # looking for mean, st.dev, and observations within st.dev for symbol1
    mean_first_pair = find_mean(first_pair_clean)
    st_dev_first = find_stdev(first_pair_clean)
    observations_within_stdev(first_pair_clean)

    print('[' + symbol2 + ']')

    # getting the symbol2 data and cleaning it
    second_pair_data = get_stock_data(symbol2, timeframe)
    second_pair_clean = clean_data(second_pair_data)

    # getting returns data (% change)
    second_pair_data['returns'] = second_pair_data['c'].astype(float).pct_change(1)
    second_pair_returns = second_pair_data['returns'].astype(float).dropna()

    # looking for mean, st.dev, and observations within st.dev for symbol2
    mean_second_pair = find_mean(second_pair_clean)
    st_dev_second = find_stdev(second_pair_clean)
    observations_within_stdev(second_pair_clean)

    print('[regression analyis]')
    b1, b0 = find_regression(symbol1, symbol2, first_pair_clean, second_pair_clean)
    find_linear_regression(first_pair_clean, second_pair_clean)
    print(f''' trade {0.01 / first_pair_clean[-1]} of {symbol1} at price {format(first_pair_clean[-1], '.8f')}  
trade {0.01 / second_pair_clean[-1]} of {symbol2} at price {second_pair_clean[-1]}''')
    print('[looking for residuals]')
    residuals_data = residuals(first_pair_clean, second_pair_clean, b1, b0)

    print('[building spread]')
    all_data = pd.DataFrame()
    all_data['first_data_close'] = (first_pair_data['c'])
    all_data['second_data_close'] = (second_pair_data['c'])
    all_data['spread'] = all_data['second_data_close'].astype(float) - b1 * all_data['first_data_close'].astype(float)
    # print(all_data)
    spread_mean = np.mean(all_data['spread'])
    spread_st_dev = np.std(all_data['spread'])
    print(f'mean of spread : {spread_mean}')
    print(f'st_dev of spread: {spread_st_dev}')

    print('[checking for stationarity of spread]')
    p_value = check_for_stationarity(all_data['spread'])
    if p_value < 0.01:
        print('[plotting graphs]')
        compile_data(symbol1, symbol2, timeframe)  # 1st graph, 2 charts together
        # draw_scatter_correlation(symbol1, symbol2, timeframe) # 2nd graph, scatter plot of 2 prices
        # plt.scatter(first_pair_returns, second_pair_returns, color='b', marker='o', s=10) # 3rd graph, scatter plot of returns
        # plt.show()
        # draw_spread(all_data, symbol1, symbol2) # 4th graph, chart of spread between 2
        draw_4_charts(symbol1, symbol2, timeframe)
    return p_value
    # add scatter correlation visuals
    # create a visual part of the analysis:
    # chart of 1st pair,
    # chart of 2nd pair,
    # scatter plot of both.
    # scatter plot of returns
    # spread of returns
    # actual spread
    # + think of more


def market_check():
    available_pairs = ['MATICBTC', 'ETHBTC', 'BNBBTC', 'LINKBTC', 'XRPBTC', 'ADABTC', 'XMRBTC', 'LTCBTC', 'EOSBTC', 'XTZBTC', 'VETBTC', 'DASHBTC', 'ATOMBTC', 'TRXBTC', 'QTUMBTC', 'NEOBTC', 'BATBTC', 'ZECBTC', 'ONTBTC', 'XLMBTC', 'ETCBTC', 'IOTABTC']
    chosen_pairs = []
    for item in available_pairs:
        for item2 in available_pairs:
            if item == item2:
                pass
            else:
                p_value = full_analysis(item, item2, '1h')

                if p_value < 0.01:
                    message = str(item) + str(item2)
                    chosen_pairs.append(message)

    print(chosen_pairs)

    chosen_pairs = [item.replace('BTC', 'BTC ') for item in chosen_pairs]
    chosen_pairs = [item.split(' ') for item in chosen_pairs]

    for item in chosen_pairs:
        del item[-1]
    print(f'pairs: {chosen_pairs}')
    coint_items = []
    for item in chosen_pairs:
        for item2 in chosen_pairs:
            if item == item2:
                pass
            if item[0] == item2[1] and item[1] == item2[0]:
                coint_items.append(item)
    print(f'cointegrated items : {coint_items}')
    for item in coint_items:
        for item2 in coint_items:
            if item[0] == item2[1] and item[1] == item2[0]:
                coint_items.remove(item)
    print(f'cointegrated items : {coint_items}')

    return coint_items


def full_graphs(timeframe, coint_items):

    watchlist = []

    print(coint_items)

    for item in coint_items:
        p_value1 = full_analysis_and_plots(item[0], item[1], timeframe)
        p_value2 = full_analysis_and_plots(item[1], item[0], timeframe)

        if p_value1 < 0.01 and p_value2 < 0.01:
            answer = input('Do you want to add item to watchlist? y/n ')
            if answer == 'y':
                watchlist.append(item)
            print(watchlist)
    return watchlist


def watcher(watchlist, timeframe):
    for item in watchlist:
        p_value, spread_mean, spread_st_dev, last_spread_data, all_data = full_analysis_watch(item[0], item[1],
                                                                                              timeframe)
        if p_value < 0.01:
            if spread_mean - (2 * spread_st_dev) >= last_spread_data:
                playsound('Ticket-machine-sound-effect.mp3')
                time.sleep(1)
                playsound('Ticket-machine-sound-effect.mp3')
                timestamp = datetime.datetime.now()
                message = [timestamp, item[0], item[1]]
                print(f'FOUND OPPORTUNITY {item[0]}{item[1]}')
                full_analysis_and_plots(item[0], item[1], timeframe)
                full_analysis_and_plots(item[1], item[0], timeframe)
                write_log(message)

            if spread_mean + (2 * spread_st_dev) <= last_spread_data:
                playsound('Ticket-machine-sound-effect.mp3')
                time.sleep(1)
                playsound('Ticket-machine-sound-effect.mp3')
                timestamp = datetime.datetime.now()
                message = [timestamp, item[0], item[1]]
                print(f'FOUND OPPORTUNITY {item[0]}{item[1]}')
                full_analysis_and_plots(item[0], item[1], timeframe)
                full_analysis_and_plots(item[1], item[0], timeframe)
                write_log(message)

            else:
                print('nothing found')
                print('nothing found')
                print('nothing found')
        time.sleep(2)




# coint_items = market_check()
watchlist = [['ETHBTC', 'XMRBTC'], ['BNBBTC', 'XLMBTC'], ['XRPBTC', 'ETHBTC'], ['XRPBTC', 'LTCBTC'], ['ADABTC', 'XMRBTC'], ['XMRBTC', 'ETHBTC'], ['XMRBTC', 'XRPBTC'], ['LTCBTC', 'XRPBTC'], ['LTCBTC', 'ADABTC'], ['XLMBTC', 'IOTABTC'], ['IOTABTC', 'BNBBTC'], ['IOTABTC', 'XRPBTC'], ['IOTABTC', 'LTCBTC']]
print(watchlist)
for item in watchlist:
    for item2 in watchlist:
        if item[0] == item2[1] and item[1] == item2[0]:
            watchlist.remove(item2)

# print(coint_items)
# watchlist = full_graphs('1h', coint_items)
write_log(watchlist)
while True:
    watcher(watchlist, '1h')
